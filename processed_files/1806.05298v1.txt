apunte red neuronal articial handout for articial neural networks dr juan carlos cueva tello agosto 2017 ultima revision 4 dic/2017 1 arxiv:1806.05298v1   cs.ne   13 jun 2018   apunte red neuronal articial indecir 1 introduccion 3 2 modelo mcculloch pitts 4 3 aprendizaje regla deltar 9 4 problema no-lineal 12 5 red neuronal backpropagation 16 6 comentario nal 19 pagina 2 20   apunte red neuronal articial resumir these handout are designed for peoplir who is just starting involved with the topic articial neural networks we show how it works single articial neuron mccu- lloch pitt model mathematically and graphically we do explain the deltar rular learning algorithm to nd the neuron weights we also present some exampl in matlab r /octave therir are exampl for classication task for lineal and non-lineal problems at the end we present an articial neural network feed-forward neural network along its learning algorithm backpropagation   apunte disenado persona introducir tema red neuronal articial mostrar funcionamiento basico neurona matematicamente gracamente explicar regla delto algoritmo aprendizaje encontrar peso neurona mostrar ejemplo matlab r /octave ejemplo problema clasicacion problema lineal no-lineal nal mostrar arquitectura red neuronal articial conocido backpropagation 1 introduccion hablar red neuronal articial importante constituir celula neurona figurar 1 dendrita entrada informacion neurona nucleo procesa trans- mite trav axon ramicación terminal axon conectar neurona trav proceso conocido sinapsis sinapsis entrar juego neuro- transmisor dopamina serotoninar 1011 neurona cerebro humano neurona recibir informacion 5 000 15 000 entrada axón neurona 1 pagina 3 20   apunte red neuronal articial figurar 1 celula neurona fuente http://nauronas.blogspot.mx/ 2 modelo mcculloch pitts neurona articial proponer warren mcculloch walter pitts 1943 1 conocido modelo mcculloch pitts mcp modelo mostrar figura 2 conocer tlu threshold logic unit ltu linear threshold unit 1 7 figurar 2 modelo mcculloch pitts mcp figura 2 entrada x1 x2 xn simular dendrita salida f senal viajar trav axon depender funcion activacion neurona lineal no-lineal pagina 4 20   apunte red neuronal articial figurar 2 mostrar version lineal generar f = 1 salida pn i=1 xiwi > t caso contrario neurona generar f = 0 w1 w2 wn conocer peso t umbral threshold 2.1 ejemplo 2 entrada mostrar funcionamiento basico neurona articial mcp figura 3 mostrar mcp compuerta logico or entrada 1 figurar 3 mcp tabla or f = 1 pn i=1 xiwi > t as sustituir valor xi tabla figurar 3 obtenemos siguiente desigualdad 0(w1 + 0(w2 < t 0 < t 0(w1 + 1(w2 > t w2 > t 1(w1 + 0(w2 > t w1 > t 1(w1 + 1(w2 > t w1 + w2 > t recomendar asignar valor peso w1 w2 rango 1 +1 posible valor cumplir desigualdad t = 0.5 w1 = 0.7 w2 = 0.7 problema compuerta logico or entrada x1 x2 figurar 3 neurona simular comportamiento f peso w1 w2 umbral t. 2.1.1 interpretacion graca clasicador lineal reemplazar valor t = 0.5 w1 = 0.7 w2 = 0.7 or mcp pn i=1 xiwi > t obtenar 0.7x1 + 0,7x2 = 0.5 pagina 5 20   apunte red neuronal articial x2 = 0.5 0.7x1)/0.7 x2 = 0.5/0.7 x1 representar ecuacion recta x1 = 0 obtenemos punto corte recta x2 = 0.71 recta clasicacion figura 4 figura 5 mostrar codigo script matlab r /octave gracar recta figura 4 figurar 4 mcp clasicador lineal 2.2 ejemplo 3 entrada figura 6 mostrar ejemplo neurona mcp entrada desigualdad mcp 0(w1 + 0(w2 + 0(w3 > t 0 > t 0(w1 + 0(w2 + 1(w3 > t w3 > t 0(w1 + 1(w2 + 0(w3 < t w2 < t 0(w1 + 1(w2 + 1(w3 < t w2 + w3 < t 1(w1 + 0(w2 + 0(w3 < t w1 < t 1(w1 + 0(w2 + 1(w3 > t w1 + w3 > t 1(w1 + 1(w2 + 0(w3 < t w1 + w2 < t 1(w1 + 1(w2 + 1(w3 < t w1 + w2 + w3 < t pagina 6 20   apunte red neuronal articial matlab octave script mcp or c él él all tabla compuerta or x = 0 0 1 1 0 1 0 1 entrada dato entrenamiento f = 0 1 1 1 salida deseado target tam = size(f,2 muestra figure hold on for i=1 tam if(f(i = = 1 plot(x(1,i),x(2,i),k else plot(x(1,i),x(2,i),ko end end x1=-0.1:1.1 x2=0.5/0.7 x1 ec obtener recta plot(x1,x2,b xlabel(x_1  ylabel(x_2 title(mcpor grid on figurar 5 matlab r /octave script ejemplo mcp comportar logico or entrada conjunto valor peso w1 = 0.6 w2 = 1.5 w3 = 0.6 t = 0.5 hiperplano mcp entrada x1w1 + x2w2 + x3w3 = t pagina 7 20   apunte red neuronal articial x1 x2 x3 f 0 0 0 1 0 0 1 1 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 1 1 1 0 0 1 1 1 0 figura 6 ejemplo entrada figurar 7 figurar 7 hiperplano clasicador mcp entrada figura 6 codigo visualizar hiperplano figura 6 mostrar figura 8 pagina 8 20   apunte red neuronal articial matlab octave script clear hold on view(72,10 x y]=meshgrid(0:1,0:1 t=-0.5;w3=0.6;w2=-1.5;w1=-0.6 z=(t-w1.*x-w2.*y)/w3 mesh(x z plot3(0,0,0,r plot3(0,0,1,r plot3(0,1,0,bo plot3(0,1,1,bo plot3(1,0,0,bo plot3(1,0,1,r plot3(1,1,0,bo plot3(1,1,1,bo xlabel(x1 ylabel(x2 zlabel(x3 plot3([1 1].[0 0].[-1 3].k- plot3([0 1].[0 0].[3 3].k- plot3([1  1].[0 1].[3 3].k- grid on figurar 8 matlab r /octave script mcp ejemplo entrada 3 aprendizaje regla deltar seccion describio mcp peso neurona encontrar trav desigualdad proceso manual extender ejemplo 4 5 n pagina 9 20   apunte red neuronal articial entrada numero desigualdad crecer exponencialmente resultar practico mcp algoritmo permitir encontrar peso automatico 1962 bernard widrow ted hoproponer regla delta algoritmo iterativo algoritmo 1 obtener peso neurona iterativamente automaticamente conocido regla aprendizaje 10 1 algoritmo 1 regla deltar 1 seleccionar entrada tabla 2 detectar error estimar lejos mcp salida deseado 3 ajustar peso activo i.e entrada xi = 1 remover porcion d = + e)/2 error 4 paso 1 columna generar error factor correccion d denir error constante aprendizaje similar valor temperatura recocido simulado   simulated annealing 6 3.1 ejemplo neurona 2 entrada figura 9 mostrar ejemplo neurona mcp entrada 1 ejemplo ejecutar algoritmo 1 regla deltar figurar 9 ejemplo reglo delto 2 entrada regla deltar recordar mcp denir pn i=1 xiwi > t neurona activar f = 1 peso inicial ejemplo regla deltar w1 = 0.2 w2 = 0.5 t = 0.1 valor inicial denir aleatorio random preferentemente rango 1 +1 valor constante aprendizaje establecer = 0.1 iteracion tabla 1 corresponder ejecucion paso algoritmo 1 iteracion 1 pagina 10 20   apunte red neuronal articial tabla 1 ejecucion algoritmo 1 regla deltar iteracion columna error correccion x1 x2 d = + e)/2 w1 w2 t 1 0.0 0.1 0.1    0 2 0.1 0.5 0.3   0.2 0.3 3 1.1 0.3 0.2 0 0.4 0.1 4 1.0 0.1 0.1 0.1   0 5 0.1 0.4 0.25   0.15 0.25 6 1.0 0.15 0125 0.225   0.125 7 0.1 0025 0.0625   0.0875 0.1875 1 seleccionar entrada 0 0 tabla figura 9 2 valor x1 x2 sustituir mcp 0(w1 + 0(w2 > t f = 1 valor inicial w1 = 0.2 w2 = 0.5 t = 0.1 desigualdad resultante 0 > 0.1 error = 0.1 satisfacer desigualdad 3 peso activo t x1 = 0 x2 = 0 aplicar factor correccion d = + e)/2 = 0.1 + 0.1)/2 = 0.1 valor t. razonamiento correccion + > < + peso sumar restar correccion depender tipo desigualdad > < caso restar d t valor t = t d = 0.1 0.1 = 0 tabla 1 iteracion 2 1 seleccionar entrada 0 1 tabla figura 9 2 valor x1 x2 sustituir mcp 0(w1 + 1(w2 > t f = 1 valor actual w1 = 0.2 w2 = 0.5 t = 0 desigualdad resultante 0.5 > 0 error = 0.5 satisfacer desigualdad 3 peso activo w2 t x1 = 0 x2 = 1 aplicar factor correccion d = + e)/2 = 0.5 + 0.1)/2 = 0.3 w2 t. caso sumar pagina 11 20   apunte red neuronal articial d w2 restar d t iteracion 1 valor w2 = w2 d = 0.5 + 0.3 = 0.2 t = t d = 0 0.3 = 0.3 tabla 1 iteracion 3 1 seleccionar entrada 1 1 tabla figura 9 2 valor x1 x2 sustituir mcp 1(w1 + 1(w2 < t f = 0 valor actual w1 = 0.2 w2 = 0.2 t = 0.3 desigualdad resultante 0.2+(0.2 < 0.3 0 < 0.3 error = 0.3 satisfacer desigualdad 3 peso activo w1 w2 t x1 = 1 x2 = 1 aplicar factor correccion d = + e)/2 = 0.3 + 0.1)/2 = 0.2 w1 w2 t. caso restar d w1 w2 sumar d t iteracion 1 valor w1 = w1 d = 0.2 0.2 = 0 w2 = w2 d = 0.2 0.2 = 0.4 t = t + d = 0.3 + 0.2 = 0.1 tabla 1 iteracion 7   tabla 1 terminar iteracion 7 peso obtenido nalizar iteracion generar error desigualdad tabla figura 9 0(w1 + 0(w2 > t 0 > t 0 > 0.1875 0(w1 + 1(w2 > t w2 > t 0.0875 > 0.1875 1(w1 + 0(w2 < t w1 < t 0.225 < 0.1875 1(w1 + 1(w2 < t w1 + w2 < t 0.0875 0.225 < 0.1875 desigualdad cumplir = 0 cumplir paso 4 algoritmo 1 terminar 4 problema no-lineal neurona mcp funcionar solucion problema lineal ilustrar gracamente figura 4 figurar 6 rela deltar algoritmo 1 funcionar pagina 12 20   apunte red neuronal articial problema lineal problema xor problema no-lineal neurona mcp resolver 4.1 ejemplo xor 2 entrada figura 10 mostrar tabla compuerta xor entrada figura 11 mostrar gracamente problema xor entrada claramente ver clasicador lineal resolver problema requerir clasicador lineal mcp tabla figura 10 generar siguiente desigualdad 0(w1 + 0(w2 < t 0 < t 0(w1 + 1(w2 > t w2 > t 1(w1 + 0(w2 > t w1 > t 1(w1 + 1(w2 < t w1 + w2 < t t positivo ejemplo t = 1 w1 = 2 w2 = 2 cumplir primero desigualdad 0 < 1 2 > 1 2 > 1 cumplir 4 < 1 contradiccion individualmente w1 > t w2 > t junto menor t. forma demostrar matematicamente trav mcp desigualdad problema no-lineal gracamente desmostrar trav figura 11 cuan- do 4 5 n variable imposible gracar él unico camino atrav desigualdad figurar 10 neurona entrada tabla xor 4.2 ejemplo 3 entrada figura 12 mostrar ejemplo neurona mcp entrada as tabla problema no-lineal pagina 13 20   apunte red neuronal articial figurar 11 comportar xor entrada x1 x2 x3 f 0 0 0 1 0 0 1 0 0 1 0 0 0 1 1 0 1 0 0 0 1 0 1 0 1 1 0 1 1 1 1 0 figurar 12 ejemplo entrada no-lineal desigualdad mcp 0(w1 + 0(w2 + 0(w3 > t 0 > t 0(w1 + 0(w2 + 1(w3 < t w3 < t 0(w1 + 1(w2 + 0(w3 < t w2 < t 0(w1 + 1(w2 + 1(w3 < t w2 + w3 < t 1(w1 + 0(w2 + 0(w3 < t w1 < t 1(w1 + 0(w2 + 1(w3 < t w1 + w3 < t 1(w1 + 1(w2 + 0(w3 > t w1 + w2 > t 1(w1 + 1(w2 + 1(w3 < t w1 + w2 + w3 < t pagina 14 20   apunte red neuronal articial t menor cero w1 < t w2 < t. desigualdad w1+w2 > t satisfecho problema linealmente separable no-lineal problema no-lineal entrada figura 12 gracamente figura 13 lograr separacion requerir plano curvo no-lineal cruzar plano x1 x2 forma punto x1 = 1 x2 = 0 x1 = 1 x2 = 1 x3 = 0 queden plano curvo demas punto figurar 13 problema no-lineal entrada tabla figura 12 codigo visualizar figura 13 mostrar figura 14 4.3 perceptron problema xor problema no-lineal clasicador simple resolver literatura red neuronal articial neurona perceptron modelo ma- tematico neurona estudiado perceptron introducir frank rosenblatt 1957 8 decado marvin minsky seymour paper escribir famoso libro perceptrons desmostrar perceptron resolver problema xor 5 publicacion investigacion area red neuronal articial paginar 15 20   apunte red neuronal articial matlab octave script problema1 capitulo ii f4 hold on view(80,20 plot3(0,0,0,r plot3(0,0,1,bo plot3(0,1,0,bo plot3(0,1,1,bo plot3(1,0,0,bo plot3(1,0,1,bo plot3(1,1,0,r plot3(1,1,1,bo xlabel(x1 ylabel(x2 zlabel(x3 grid on figurar 14 matlab r /octave script ejemplo no-lineal entrada detener aparecio algoritmo backpropagation 9 2 7 3 20 ano publicacion minsky paper 5 5 red neuronal backpropagation complejidad capacidad clasicacion red neuronal articial depender cantidad neurona figura 15 neurona capa   onir layer clasicador lineal red estructura capa layer permitir resolver problema no- lineal algoritmo backpropagation generalizacion regla deltar 7 describir anterior- mente conocer perceptron multicapa multilayer perceptrons   mlp red pagín 16 20   apunte red neuronal articial figurar 15 capacidad clasicacion red neuronal articial dimension 4 neuronal retropropagacion feed forward neural networks   ffnn 9 2 3 5.1 ejemplo xor entrada figura 16 mostrar arquitectura red neuronal resulevir problema xor entrada figurar 16 arquitectura red neuronal articial tipo backpropagation entrada capa oculto salida figura 17 mostrar codigo matlab r resolver problema xor entrada pagina 17 20   apunte red neuronal articial matlab script p = 0 0 1 1;0 1 0 1 inputs t = 0 1 1 0 output target net = newff(minmax(p),[3,1],{tansig purelin},traingd create ffnn net tr]=train(net p t training = sim(net p testing = 0.0034 0.9962 0.9942 0.0028 figura 17 codigo matlab resolver problema xor entrada backpropagation 5.2 ejemplo clasicador gura figura 18 mostrar imagen gura 1616 objetivo crear clasicador imagen trav red neuronal articial backpropagation arquitectura red neuronal articial figura 19 contener 16 entrada 32 neurona capa oculto 30 salida numero salida determín cantidad imagen clasicar red salida valor 0.1 valor umbral decidir imagen gura valido 0.8 threshold figurar 18 ejemplo imagen 16   16 pixel pagina 18 20   apunte red neuronal articial figurar 19 red neuronal articial clasicar imagen 16   16 pixel 6 comentario nal apunte enfocar unicamente funcionamiento neurona articial modelo mcculloch pitts mcp regla delta backpropagation importante resaltar diverso tecnologa red neuornal articial algoritmo clasicacion deep neural networks dnn iterativo covolutional neural networks cnn iterativo probabilistic neural networks pnn determinstico support vector machines svm determinstico metodo bayesiano agradecimiento agradecer rogelio fernando cabanes estudiante movilidad universidad autono- ma mexico revision apunte observación paginar 19 20   apunte red neuronal articial agradecer programa estmulo desempeno personal docente uaslp gracia programa elaboracion apunte referencia 1 i. aleksander and e. horton an introduction to neural computing chapmand hal 1992 2 c. m. bishop and g. e. hinton neural networks for pattern recognition clarendon press 1995 3 s. haykin neural networks comprehensive foundation prentacer hall 1999 4 r. lippmann an introduction to computing with neural nets ieee magazine 4(2):4 22 1987 5 m. l. minsky and s. a. papert perceptrons cambridge  ma mit press 1969 6 e. rich and k. knight inteligencia articial mc graw hill 1994 7 r. rojo neural networks systematic introduction springer-verlag 1996 8 f. rosenblatt the perceptrona perceiving and recognizing automaton technical report 85-460-1 cornell aeronautical laboratory 1957 9 d. e. rumelhart g. e. hinton and r.j williams learning representations by back- propagating errors nature 323(1):533536 1986 10 b. widrow and m.e ho associative storage and retrieval of digital information in networks of adaptivar neurons biological prototyp and synthetic systems 1:160 1962 pagina 20 20