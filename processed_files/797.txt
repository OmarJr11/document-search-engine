arán carlos working paper red neuronal recurrente anlisis modelo especializado dato secuencial serie documento trabajo provided in cooperation with university of cemo aires suggested citation arán carlos red neuronal recurrente anlisis modelo especializado dato secuencial serie documento trabajo universidad centro estudio macroeconmico argentina ucema aires this version is available at die dokumente auf econstor drfen zu eigenir wissenschaftlichen zwecken und zum privatgebrauch gespeichert und kopiert werden sie drfen die dokumente nicht fr ffentliche oder kommerzielle zwecke vervielfltigen ffentlich ausstellen ffentlich zugnglich machen vertreibir oder anderweitig nutzen sofern die verfasser die dokumente unter insbesondere zur verfgung gestellt haben solltar geltir abweichend von dar nutzungsbedingungen die in der dort genanntir lizenz gewhrten nutzungsrechte terms of usar documents in econstor may be saved and copied for your personal and scholarly purpós you are not to copy documents for public or commercial purpós to exhibit the documents publicly to make them publicly available on the internet or to distribute or otherwise usar the documents in public if the documents have been made available under an opir content licence especially creativir commons licenz you may exercise further usage rights as specified in the indicated licence universidad cema aires argentino serie documento trabajo rea ingenierar red neuronal recurrente anlisis modelo especializado dato secuencial carlos arán junio nro ucema av crdobar aires argentina issn impreso issn lnea editor jorge streb asistente editorial valerio dowding red neuronal recurrente anlisis modelo especializado dato secuencial carlos arán mayo resumir aprendizaje automtico rama inteligencia artificial ia especializar inferir patrón conjunto dato utilizar tcnica estadstica heurstica mtodo tradicional aprendizaje automtico estn limitado capacidad procesamiento dato bruto necesidad contar intenso trabajo previo procesamiento inferencia aprendizaje profundo clase mtodo aprendizaje automtico mltipl nivel representacin solucionar dificultad componer mdulo sencillo lineal generar sucesivamente representación nivel superior ligeramente ms abstracta caracterstica desarrollado nivel anterior empezar entrada bruto artculo analizar profundidad caracterstica aplicación red neuronal recurrente rnn clase estructura aprendizaje profundo especializar tratamiento dato tipo secuencial caracterizar serie temporal estructura dato texto video audio artculo presentarn analizarn profundidad caracterstica aplicacin tipo red neuronal profundo especializado tipo dato red neuronal recurrente red memoria corto plazo lstm red recurrente atencin ingeniero industrial uba doctor ingeniera industrial cand profesor materia mtodo cuantitativo ciencia dato negocio maestra direccin empresa made ucema director posgrado ciencia dato big datar facultad ingeniera universidad aires desempear consultor especializado inteligencia artificial aplicación negocio industria punto vista autor representar necesariamente posicin universidad cema aprendizaje automtico aprendizaje profundo algoritmo machine learning aprendizaje automtico basar aprendizaje muestra dato patrón relación funcional distinto variable mitchell ofrecer definicin programa ordenador aprender experiencia clase tarea t medida rendimiento p rendimiento tarea t medido p mejora experiencia tarea aprendizaje automtico generalmente describir trmino cmo sistema aprendizaje automtico deberar procesar ejemplo ejemplo caso jerga machine learning observacin medida valor variable tipo cuantitativas relevar caracterstica variable tipo categrico cualitativo general representar ejemplo vector entrada i vector valor variable conjunto entrenamiento validacin medida performance tarea clasificacin generacin caso precisin simplemente proporcin ejemplo modelo producir salida correcto caso clasificacin conocer valor variable objetivo caso utilizado entrenar modelo poder comparar prediccin salida modelo valor correcto modelo generacin dato momento entrenarlo estaramos utilizar dato entrenamiento corroborar qu parecido dato entrenamiento utilizado dato generado general interesar cmo funcionar algoritmo aprendizaje automtico dato ver determín cmo funcionar implemente mundo real evaluar medida rendimiento utilizar conjunto dato est separado dato utilizado entrenamiento sistema aprendizaje automtico procedimiento cabo separar set original subconjunto correr proceso asociado entrenamiento modelo clasificacin generacin slo corroboraremo efectividad medirer performance tarea separacin correspondiente tarea realizado subconjunto generado entrenamiento validacin proceso respectivamente fundamental proceso aprendizaje automtico clave radicar efectividad procedimiento validez capacidad generalizacin modelo tipo aprendizaje automtico algoritmo aprendizaje automtico clasificar él rasgo supervisado supervisado funcin tipo proceso permitir fase entrenamiento aprendizaje algoritmo aprendizaje supervisado aprender propiedad til estructura conjunto dato contexto aprendizaje profundo normalmente aprender distribucin probabilidad gener conjunto dato explcitamente estimacin densidad implcitamente tarea generacin dato sinterizado algoritmo aprendizaje supervisado desempean función clustering consistir dividir conjunto dato grupo aglutinir ejemplo caracterstica similar separir grupo s algoritmo aprendizaje supervisado realizar proceso conjunto dato caracterstica atributo caso contar dato fundamental conocer valor variable objetivo jerga disciplina soler denominar clase rasgo aprendizaje supervisado consistir observar ejemplo vector aleatorio intentar aprender implcita explcitamente distribucin probabilidad propiedad interesante distribucin aprendizaje supervisado consistir observacin ejemplo vector aleatorio valor vector asociado aprender predecir normalmente estimar funcin distribucin pobabildiad condicional trmino aprendizaje supervisado origen idea objetivo clase proporcionar supervisor mostrar sistema aprendizaje automtico aprendizaje supervisado supervisor algoritmo aprender sentido dato gua forma comn describir conjunto dato observación dataset matriz diseo matriz diseo matriz contener ejemplo fila columna matriz corresponder caracterstica algoritmo aprendizaje diferenciar funcin forma operar procesa dato contenido matriz diseo red neuronal red neuronal artificial rna inspirar estructura neuronal biolgica encontrar cerebro humano red contener capa organizado unidad interconectado nodo rna utilizar principalmente tarea difcil derivar restricción lgica forma explcito reconocimiento patrón anlisis predictivo modelo computacional rna desarrollar mcculloch pitts neurocientfico lgico respectivamente proponer unidad umbral binario modelo neurona artificial modelo matemtico unidad funcin activacin caso funcin escaln heaviside umbral xj seal entrada wj peso asociado j n corresponder nmero entrada salida unidad suma est umbral caso contrario modelo llev rosenblatt desarrollar red neuronal pionerar conocido perceptrn modelo actual rna consistir suma ponderado entrada sesgo bia suma someter funcin lineal producir salida nodo neurona ver él figura estructura nodo neurona rna mencionar rna conjunto neurona organizado capas analizar él grafo dirigido ponderado neurona nodo grafo arista conexión salida neurona entrada capa rna tipo perceptrn capa entrada capa oculto capa salida ms capa oculto denominacin red cambio convertir red neuronal profundo figura comprobar organizacin capa rna interconectado figurar red neuronal artificial multicapar red neuronal recurrente rnn red neuronal recurrente rnn clase aprendizaje profundo basado trabajo david rumelhart rnn conocer capacidad procesar obtener informacin dato secuencial anlisis vdeo subtitulacin imgén procesamiento lenguaje natural pln anlisis msica depender capacidad red neuronal recurrente diferencia red neuronal artificial vistas asumir independencia dato entrada rnn capturar activamente dependencia secuencial temporal atributo ms definitorio rnn comparticin parmetro compartir parmetro modelo asignarar parmetro nico representar dato secuencia podrar inferencia secuencia longitud variable impacto limitacin observar él forma notorio procesamiento lenguaje natural red multicapo tradicional red multicapo tradicional fallara crear interpretacin lenguaje parmetro nico establecido posicin palabra frase rnn serar ms adecuado tarea compartir peso dato espaciado secuencialmente lenguaje palabra frase diagrama grafo cclico red neuronal recurrente imagen extrado rnn generalmente aumentar arquitectura red multicapo convencional adicin ciclo conectar nodo adyacente paso tiempo ciclo constituir memoria interno red utilizar evaluar propiedad dato actual dato inmediato tambin importante mayora red neuronal convencional tipo perceptrn tambin llamado feedforward estn limitado mapeo entrada salida rnn mapeo ejemplo traducir ejemplo identificar voz utilizar grafo computacional representar mapeo entrada salida prdida desplegar grfico cadena evento obtener imagen claro reparto parmetro red ver figura figurar imagen extrado ecuacin generalizado relación recurrencia indicar sistema depender paso tiempo indicado t ecuacin reescribir él representar entrada instancia tiempo particular importancia representacin aspecto relevante secuencia entrada t topologa red neuronal recurrente depender problema tratar resolver red podr trabajar tipo secuencia entrada salida ejemplo analicemos caso problema anlisis serie temporal mercado red deber tomar entrada valor acción ltimo das predecir valor variante seriar caso predecir valor das basndo él valor ejemplo perspectiva red neuronal recurrente elegir topologa adecuado definir topologa principal figura mostrar topologa imagen mostrar capa neurona recurrente desarrollado tiempo slo salida ltimo time step tomado salida capa topologa tipo imagen extrado figura presentar topologa capa devolver resultado procesado perodo tiempo usualmente red neuronal recurrente profundo buscar comportamiento tipo desear acoplar capa tipo sequence ltimo capa tipo consecuencia estructura salida red nico elemento calcular funcin resto time steps lote figurar topologa rnn imagen extrado ltima arquitectura unin ver él figura modelo encoder tomar entrada secuencia generar ltimo instancia representacin vectorial modelo modelo decoder tomar dicho representacin vectorial entrada devolver resultado procesamiento perodo tiempo modelo global ver él longitud secuencia entrada variar secuencia salida til problema traduccin automtico frase idioma determinado ms smbolo palabra homloga idioma tipo modelo estn tener relevancia significativo campo procesamiento lenguaje natural composicin automtico musico aparicin mecanismo attention cuyo inclusin modelo result arquitectura transformer figurar topologa tipo imagen extrado problema red neuronal recurrente momento ver cmo funcionar celda memoria ms bsicas celda rnn tpica tipo estructura problema llamado memory problema deriva conocido problema asociado desvanecimiento gradiente explicar red neuronal recurrente basar funcionamiento procesado secuencia informacin agregar cmputo elemento secuencia resultado anlisis elemento resultado rnn funcin agregar procesamiento elemento secuencia medida red procés ms elemento cadena problema recordar informacin problema surgir consecuencia proceso matemtico red neuronal recurrente capaz entrenar él aro corpus algoritmo propagacin atrs tiempo through time medida rnn recibir elemento secuencia desarrollar time steps gradiente error propagar atrs har percepcin multicapa clsico suceder tipo red medida gradiente alcanzar capa ms cercano input caso rnn perodo procesado decae exponencialmente rnn ms sencillo capaz aprender patrón extendido tiempo eficaz rango corto ejemplo secuencia elemento mitigar problema memory aparecer tipo celda memoria s capaz extraer patrón secuencia longitud celda ms complejo conocer celda memoria corto plazo lstm sigla ingls short term memory red memoria corto largo lstm red neuronal memoria corto plazo lstm tipo particular rnn solucionar problema rnn asociado memoria corto plazo desvanecimiento decaimiento gradiente explosin ver superar dificultad celda tipo lstm figura recuadro punteado corresponder unidad red lugar mostrar componente lstm izquierda informacin procedente procesamiento dato asociado perodo utilizar estructura dato caso tipo tensor arreglo dato ms dimensión inferior entrada informacin unidad derecha tensor salir informar unidad tiempo rnn simple informacin diagrama predecir palabra prdida superior derecho figurar arquitectura celda lstm imagen extrado objetivo mejorar memoria rnn evento pasado entrenndolo recordar importante olvidir resto lstm procesar versión memoria selectivo social est superior versin ms local inferior lneo tiempo memoria superior llamar clula abreviar lneo inferior llamar figura introducir conectiva función activacin lugar ver lnea memoria modificar lugar pasar unidad tiempo estn etiquetado tiempo x idea memoria eliminar unidad tiempo x aadir unidad qu decir mirar incrustacin informacin actual venir inferior izquierdo pasar capa unidad lineal seguido funcin activacin sigmoidea indicar anotacin w b w b formar combinacin lineal s funcin sigmoidear neurona clsico notacin matemtico operacin utilizar punto central indicar concatenacin vector repetir inferior izquierda concatenar lneo h ht dato actual obtener introducir unidad lineal olvido seguido sigmoidea producir f seal olvido desplazar izquierdo figura salida sigmoidea multiplicar elemento elemento memorio venir superior izquierdo elemento elemento ejemplo j elemento matriz multiplicar j elemento ecuacin operacin representar as sigmoid estn limitado cero resultado multiplicacin reduccin valor absoluto punto memoria principal corresponder olvido general conjuracin sigmoidear alimentar multiplicacin patrn comn compuerta suave contrastar suceder unidad aditivo memoria dato llegar abajo izquierdo pasar separado travs capa lineal activacin sigmoidea funcin activacin tanh mostrar figura tanh significar tangente hiperblico importante diferencia funcin sigmoidear tanh salida valor positivo negativo arrojar valor lugar slo escalar dato entrada resultado aadar celda celda etiquetado figurar funcin tanh tangente hiperblico despu lnea memoria dividir copia salir derecha copia pasar tanh combinar transformacin lineal historia valor actual convertir él lneo h inferior concatenar entrada proceso repetir punto destacar aqu lnea memoria celda pasar directamente unidad lineal memoria desvirtuar olvidar unidad x aadir informacin dato actual habr operación matemtica combinacin lineal escalamiento transformacin lineal mecanismo attention mecanismo attention presentar dzmitry bahdanauet extensin mejorar rendimiento modelo encoder decoder tarea traduccin automticar encoder decoder convencional encoder representar vector tamao fijo oculto informacin frase entrada palabra autor rendimiento encoder decoder bsico decae rpidamente medida longitud cadena entrada crecer mecanismo attention pretender solventar precisamente problema tcnica conjunto vector generar lugar vector dimensin fijo dicho vector seleccionar subconjunto cercano trmino pretender traducir time step figurar arquitectura attention imagen extrado figura ver él esquema arquitectura intentar generar palabra objetivo yt dar frase xt ver lugar mantener vector oculto celda ltimo step encoder considerar salida intermedio momento computar suma ponderado dicho vector intermedio clculo permitir determinar qu palabra sern ms relevant decoder step propuesta basado mecanismo visual attention proponer ao xuet et objetivo propuesta consista sistema capaz alinear imagen entrada producir palabra describir salida arquitectura consista red convolucional extraa caracterstica imagen continuacin red recurrente mecanismo atencin salida palabra mecanismo attention focalizar él elemento imagen quelar definir frase salida corresponder dicho elemento herarchical attention propuesta llego mano yanget sistema clasificacin documento aplicar mecanismo attention nivel arquitectura presentar mdulo encoder decoder attention aplicado nivel frase nivel palabra transformer consecuencia ms interesante aparicin mecanismo attention aparicin modelo transformer propuesto vaswaniet arquitectura suponer nivel mejora campo procesamiento lenguaje natural tipo sistema permitir alinear palabra secuencia calcular representacin dicho secuencia ms preciso eficiente anterior modelo aplicación lstm continuacin presentar aplicación red recurrente evidenciar manea contundente performance aplicacin red ms notorio presentndo él paper cientfico novedoso aplicación red particular transform ver aplicación ms emblemtica generacin automticar subttu él imgén subtitulado automtico imgén tarea dar imagen sistema generar pie foto describir contenido imagen producir explosin algoritmo deep learning lograr resultado impresionante problema aprovechar trabajo mejor modelo clasificacin deteccin objeto fotografas detectar objeto fotografas generar etiqueta objeto paso convertir etiqueta descripcin frase inteligibl sistema involucrado entrenir red neuronal convolucional profundo deteccin objeto fotografa utilizar red recurrente lstm convertir etiqueta frase coherente traduccin automtico texto modelo aprender traduccin palabra contexto modificar traduccin soportar secuencia entrada salido variar longitud general generacin automticar texto manuscrito tarea corpus ejemplo escritura generar palabra frase determinado escritura proporcionar secuencia coordenada utilizado bolgrafo crear muestra escritura corpus aprender relacin movimiento bolgrafo letra generar generar ejemplo aplicacin tcnica aprender estilo imitarlo generacin automtico partitura musical literatura encontrar ejemplo tipo arquitectura aplicado caso composicin musical ejemplo limet proponer sistema basado lstm bidireccional blstm generar acompaamiento musical forma progresin acorde dar melodo arquitectura consista red bidireccional capa lstm celda red entrenar corpus partitura msica moderno rock jazz pop resultar canción representar nota meloda tener posible valor cont octava extra acord nicamente usar triada entrenamiento llev cabo presentar red grupo tiempo negro meloda comparar salida acord correspondiente fase generacin iterativamente pas red cadena tiempo concatenar acord salida progresin completo autor comparar sistema modelo evaluar cuantitativamente matriz confusin cualitativamente oyente resultado mostrar precisin modelo as tendencia usuario elegir composición frente modelo conclusión modelo aprendizaje automtico clsico supervisado supervisado exigir algn tipo control conocimiento caracterstica atributo medido relevado intentar desarrollar modelo predictivo descriptivo conocer representación realidad subyacente entorno anlisis expresado variable asumir independiente s poder aplicar ms variado tcnica ajuste estimar parmetro funcin arribar resultado buscado prediccin agrupamiento obstante caso representación atributo presentar formato estructurado caso fragmento texto imgén audio video caso representación generado algortmica proceso generar abstracción nivel particularidad consecuencia deseable estn sumamente correlacionada pxel imagen palabra texto nota musical sonido archivo audio precisar modelo cuyo configuracin encuentre preparado lidiar representación nivel altamente correlacionada solucin encontrar modelo redes neuronal artificial especial utilizar tcnica aprendizaje profundo deep learning construido emular estructura conexión sinptica cerebro humano arquitectura aprendizaje profundo utilizar forma ubicua extraccin caracterstica anlisis patrón abstraccin dato representacin sucesivo concatenado complejidad creciente demostrar modelo rendir ms rpido actual tcnica anlisis ltima generacin tarea aprendizaje supervisado supervisad configuración arquitectura red neuronal aprendizaje profundo poseer caracterstico destacar conferir particular destacado utilidad modelo aprendizaje profundo analizado artculo red neuronal recurrente rnn sigla ingls especializado tratamiento informacin presentado forma secuencial variable corte longitudinal definicin encontrar lenguaje natural simblico seal audio vo hablado msico video serie temporal arquitectura red neuronal recurrente presentar progresivo funcin aparicin escena cientfico mejora aportar configuración preceder as arribar modelo ms utilizado actualidad red memoria corto plazo lstm transformer configuración sofisticado red recurrente sortear dificultad perdido memoria optimizacin funcin objetivo inherente rnn clsica asegurar as performance posicionar estndar actual arquitectita deep learning especializado modelados informacin corte longitudinal artculo finalizar parentacin aplicación emblemtica red recurrente tipo lstm bibliografa mitchell machine learning new york yegnanarayana artificial neural networks phi learning pvt ltd mcculloch and pitts logical calculus of the ideas immanent in nervous activity the bulletin of mathematical biophysics pp rosenblatt  the perceptron probabilistic model for information storage and organization in the brain psychological review goodfellow bengio courville deep learning mit press yunghyun cho bart merrinboer caglar gulcehre dzmitry bahdanau fethibougar holger schwenk and yoshua bengio learning phrar representationsusing rnn for statistical machine preprint ashish vaswani noam shazeer niki parmar jakob uszkoreit llion jones aidar ngomez ukasz kaiser and illia polosukhin attention is all you need inadvancesin neural information processing systems pag sepp hochreiter and jrgen schmidhuber long sepp hochreiter untersuchungen zu dynamischir neuronalen technische universitt mnchar ronald j williams and david zipser learning algorithms for theory architectur and applications mike schuster and kuldip k paliwal bidirectional recurrent neural on signal processing dzmitry bahdanau kyunghyun cho and yoshua bengio neural machine translation by jointly learning to align and preprint xu jimmy ba ryar kiro kyunghyun cho aar courville ruslar rich zemel and yoshua bengio show attend and tell neural imagecaption generation with visual attention ininternational conference on machinelearning pages zichao yang diyi yang chris dyer xiaodong alex smola and eduard attention networks for document classification inproceedings of conference of the north americar chapter of the association for computationallinguistics human language technologies pag zichao yang diyi yang chris dyer xiaodong alex smola and eduard attention networks for document classification inproceedings of conference of the north americar chapter of the association for computationallinguistics human language technologies pag show and tell neural image caption generator grave generating sequences with recurrent neural networks corr hyungui lim seungyeon rhyu and kyogu lee chord generation from symbolicmelody using blstm preprint charniak  introduction to deep learning