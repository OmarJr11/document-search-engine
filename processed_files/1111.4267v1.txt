control neuronal modelo inverso servosistema usar algoritmo aprendizaje levenberg-marquardt bayesiano victor a. rodriguez-toro   jaime e. garzn jess a. lpez viii congreso asociacin colombiano automtica universidad tecnolgico bolvar asociacin colombiano   automtica abril 2-3 2009 cartagena isbn 978-958-8387-23-9    1     control neuronal modelo inverso servosistema usar algoritmo   aprendizaje levenberg-marquardt bayesiano     victor a. rodriguez-toro jaime e. garzn   jess a. lpez     grupo investigacin bionanoelectrnica escuela ingeniera elctrico electrnico   a.a 25360 universidad valle cali colombia email victor.rodriguez@correounivalle.edu.co      escuela ingeniera elctrico electrnico    a.a 25360 universidad valle cali colombia email jaimeegv@hotmail.com     grupo investigacin energa gien-uao departamento automtica electrnico   calle 25 115-85 universidad autnoma occidente cali colombia e-mail jalopez@uao.edu.co     resumen trabajo presentar resultado experimental control neuronal velocidad   servosistema estrategia control neuronal implementado control modelo inverso   entrenamiento red usar algoritmo aprendizaje levenberg-marquardt   regularizacin bayesián evalar capacidad generalizacin mtodo funcin   correcto funcionamiento controlador seguir seal referencia esfuerzo control   obtenido    palabra clave neuro-control red neuronal artificial algoritmo entrenamiento control   dinmica inverso      1 introduccin   propiedad ms explotada red   neuronal artificial rna aproximador   universal función hornik 89 llevar   utilizarlas diversidad aplicación   reconocimiento     patrón   bishop   95       identificacin control sistema dinmico narendra   90      rea control sistema dinmico rna   usar enfoque control neuronal   modelo inverso estrategia bsico control neuronal   norgaard 00      adems sealar él existir   diversidad algoritmo aprendizaje red   neuronal ms usado algoritmo   basado gradiente depender   utilizar informacin gradiente algoritmo   aprendizaje denominado orden gradiente   descendente hacer 96 haykin 99 algoritmo   aprendizaje ms elaborado denominado orden   algoritmo gradiente conjugado hacer 96   haykin 99   algoritmo basado metodologa   levenberg-marquardt hacer 96 masters 95      aplicación control neuronal modelo inverso   generalmente seleccionar algoritmo aprendizaje   basado levenberg-marquardt principalmente   rapidez convergencia error suficientemente   pequeo acorde necesidad usuario   alcanzar error pequeo garantizar capacidad   generalizacin modelo neuronal producir   caso problema sobre-entrenamiento significar     red presentar error patrón   entrenamiento error aumentar patrón   validacin      alternativa evitar sobre- entrenamiento destacar algoritmo regularizacin   automtico aprendizaje bayesiano aplicación   identificacin sistema explorar tener   resultado calidad modelo neuronal   mejorar aprendizaje bayesiano   aprendizaje   convencional     levenberg-marquardt   lopez 07     objetivo trabajo diferencia   controlador neuronal entrenado mtodo   garantizar capacidad     generalizacin     levenberg-marquardt mtodo considerar   aspecto aprendizaje bayesiano documento est   organizado seccin 2   presentar concepto general control neuronal   entrenamiento red neuronal considerar   sobre-entrenamiento posteriormente seccin 3   presentar implementacin control neuronal modelo   inverso servosistema seccin 4 mostrar   resultado experimental trabajo terminar seccin 5   presentar conclusión        2       2 control modelo inverso aprendizaje   levenberg-marquardt bayesiano   2.1   modelo inverso   control modelo inverso tcnico buscar   cancelar dinmica planta colocar elemento   cascado caso red neuronal   aproximacin matemtico inverso planta   buscar salida ms parecida   referencia norgaard 00     tendencia realizar control neuronal   modelo   inverso           conocido     entrenamiento general red neuronal usar dato   obtenido anterioridad modelo inverso   planta red neuronal entrenar   controlador cancelar dinmica   planta observar fig. 1      fig. 1 esquema control modelo inverso         tendencia   conocido     entrenamiento   especializado esquema control adaptativo    objetivo minimizar error salida planta   y(k salida modelo referencia ym(k norgaard   00 entrenamiento requerir red neuronal   entrenado modelo directo planta fig. 2                             fig. 2 estructura entrenamiento inversoespecializado     2.2   algoritmo aprendizaje levenberg-marquardt lm   ecuacin 1 presentar cmo localizar valor   mnimo xmin funcin variable f(x utilizar   derivado mtodo   newton    1 min min min min t x f t x f t x t x   = +                    1   base ecuacin inferir 2   minimizar error global ep espacio peso   sinptico representado matriz w.    1 p p t t   = + w w                      2   derivada error global ep corresponder   matriz hessián h derivada ep conocer   vector gradiente g. vector gradiente matriz   hessián funcin error calcular   utilizar regla cadena   as vector gradiente est   compuesto derivado parcial error   peso wi red elemento i j   matriz hessián calcular segundo derivado   parcial error peso   wi   wj    carga computacional implicar calcular   exacto matriz h estimacin   master 95 2 introducir   mecanismo control evitar problema   poder actualizacin pesos red dar   origen 3           g i h w w 1 1   +   = +   t t           3   mecanismo control garantizar convergencia   algoritmo consistir introducir factor i. lugar   probar ecuacin   mtodo newton     evaluar él algoritmo converge valor error   comenzar crecer eliminar valor incrementar   valor   3 minimizar efecto   matriz h actualizacin peso     efecto matriz h prcticamente desaparecer   actualizacin peso esencialmente   algoritmo gradiente descendente algoritmo   claro tendencia convergencia disminuir valor     aumentar efecto matriz h   garantizar algoritmo comportar   predominio mtodo newton    mtodo levenberg marquardt mezclar sutilmente   mtodo newton mtodo gradiente descendente   nico ecuacin estimar actualizacin peso   red neuronal   2.3 regularizacin algoritmo aprendizaje   regularizacin bayesián br     aplicación observar red neuronal   artificial caer problema conocido   sobre-entrenamiento bishop 95 red capaz   responder adecuadamente dato entrada   dato utilizar proceso aprendizaje   problema solucionar   visto red especializar memorizar   conjunto dato determinado error pequeo    sobre-entrenamiento traer consecuencia   error test verificacin red   planta rna modelo inverso rnar modelo directo u(k salido y(k entrada r(k + e(k modelo   referencia ym(k salido estimado eu(k     3       entrenamiento indeseable red est   trabajar solucin aplicacin especfico    surgir tcnica denominado regularizacin cuyo   objetivo minimizar fenmeno sobre-entrenamiento   ende efecto fenmeno sobre-entrenamiento   ms evidente dato entrada estn   contaminado ruido objetivo regularizacin   garantizar adecuado aprendizaje evitar problema    2.3.1 regularizacin parada temprano   proceso aprendizaje definir tipo error   aprendizaje   cuyo evolucin mostrir   figura 3 lnea continuo calcular   diferencia salida red valor deseado   error utilizar modificar peso red    tcnica surgir error   denomina validacin cuyo evolucin mostrar   lneo punteado calcular   diferencia salida red valor deseado   evaluado dato entrada pertenecer conjunto   dato validacin importante aclarar error   modificacin peso sinptico red   momento observar comportamiento   red frente dato pertenecer conjunto   universo problema utilizado   entrenamiento   0 1 2 3 4 5 6 7 8 9 10 10 -4 10 -3 10 -2 10 -1 10 0 10 1 iteración error cuadrtico    fig. 3 regularizacin parada temprano lneo continuo error   entrenamiento lneo punteado error validacin     fig. 3 observar error entrenamiento   seguir decreceir error validacin   comenz subir seal sobre-entrenamiento   evitar él recomendar detener proceso   entrenamiento red   justo error   validacin empiecir tendencia ascendente   razn llamar regularizacin parada temprano   bishop 95 evitar proceso   aprendizaje contine disminuir excesivamente error   entrenamiento tomar criterio finalizacin   tendencia ascendente error validacin       2.3.2 regularizacin limitacin magnitud   peso   experiencia mostrar garantizar   funcin salida suave lograr mantener peso   sinptico red valor relativamente pequeo   bishop 95 limitar magnitud peso   redefinar clculo error as           w d r    + =           4   4 error calcular trmino   utilizar notacin   denominar er     error regularizado trmino corresponder   error cuadrtico promedio presentado 5 forma   tradicionalmente estimar error   entrenamiento afectado parmetro     = =   = m k pk pk p p d d p 1 2 1 2 1             5   trmino utilizado estimar error   aprendizaje regularizado introducir sumatoria peso   sinptico red mostrado 6 ponderado   parmetro algoritmo aprendizaje tender   minimizar er resultado sumatoria   peso igualmente tender minimizar garantizar   suavidad salida red    = = n n n w w 1 2              6   2.3.3 regularizacin bayesián   trabajar tcnica error regularizado mostrado 4   inconveniente definir parmetro      conseguir efecto minimizar   sobre-entrenamiento lopez 05 regularizacin bayesián   tcnica entrenamientir red neuronal   abordo perspectiva probabilstico   distribucin probabilidad valor   peso mackay 96 tcnica regularizacin   tambin denominar regularizacin automticar   trabajar error regularizado forma   algoritmo aprendizaje valor ms   adecuado parmetro regularizant     foresee   97   3 control neuronal modelo inverso   motor dc   3.1   servosistema motor dc   proceso controlar utiliz motor dc cuyo   eje est acoplado disco pretender controlar   velocidad rotacin planta dato   enviar pc motor travs tarjeta   adecuacin registro directo      4       permanente velocidad obtenido   tacmetro   fig. 4 observar fotografa   servosistema controlar         fig. 4 servomecanismo controlar     servosistema poseer zona muerto   2.5v zona saturacin detectado 6.5v   par valor convertir cota superior inferior   proceso identificacin entrenamiento red   neuronal accin control operar forma   deseado rango trabajo     3.2 control neuronal modelo inverso motor dc     idea control tcnica neuronal   inicialmente planteado narenda 90 objetivo   aprovechar capacidad aprendizaje red   neuronal entrenar red poder usar   controlador   inicialmente realizar control modelo inverso   norgaard 00 modelo inverso caso estudio   red neuronal convenientemente entrenado hacer   labor controlador    3.2.1 arquitectura interno red neuronal   red neuronal realizar control red tipo   perceptron multicapa capa oculto red 5   entrada valor referencia muestra actual   salida sistema muestra salida   sistema muestra accin control   accin control retardo ref(k),y(k),y(k-1),u(k- 1).u(k-2 informacin red estimar accin   control aplicar proceso u(k capa oculto est   conformado neurona función   activacin tangente-sigmoidal    3.3   descripcin experimento   definir experimento realiz prueba   estable identificar zona muerto zona   saturacin determinar regin operacin motor   mencion seccin 3.1 valor estn   2.5v 6.5v respectivamente   3.3.1 toma dato   entrenar controlador neuronal modelo inverso   experimento   tomar dato funcionamiento motor regin   operacin    experimento aplicar escalón amplitud   aleatorio motor duracin escaln   garantizar estabilizacin velocidad motor usar   tarjeta adquisicin dato capturan seal   entrada salida velocidad servomecanismo   realizacin experimento herramienta   labview   3.3.2 entrenamientir red neuronal   esquema control neuronal utilizado control   neuronal inverso general caso modelo inverso   entrar off-line usar toolbox red   neuronal matlab    entrenamiento red neuronal utiliz   mtodo entrenamiento aprendizaje basado   levenberg marquardt aprendizaje regularizacin   bayesián    4 resultado experimental   entrenar red neuronal estrategia   entrenamiento mencionado proceder verificar   comportamiento neuro-controlador obtenido   verificacin implement aplicacin   herramienta labview tomar peso red   neuronal entrenado matlab neuro- controlador inverso usar esquema similar   figura 1     valer pena mencionar red probado   neuro-controlador obtener error entrenamiento   similar verificar   pruer controlar planta capacidad   generalizacin     4.1 control inverso entrenado levenberg marquardt   neuro-controlador usar   servosistema obtenido entrenamiento   basado metodologa   levenberg marquardt      figura 5 6 observar comportamiento tpico   neuro-controlador observar   funcionamiento ms adecuado lograr   seguimiento seal referencia esfuerzo   control oscilatorio          5           fig. 5 respuesta temporal neuro-controlador entrenado levenberg   marquardt lneo punteado referencia lneo definido salida planta           fig. 6 respuesta temporal esfuerzo control neuro-controlador   entrenado levenberg marquardt     realizar prueba entrenamiento   metodologa encontrar   cumplierar       satisfactorio     control     servosistema figura 7 8 observar neuro- controlador obtenido lograr seguimiento   seal referencia caso esfuerzo   control seguir oscilatorio         fig. 7 respuesta temporal neuro-controlador entrenado levenberg   marquardt lneo punteado referencia lneo definido salida planta         fig. 8 respuesta temporal esfuerzo control neuro-controlador   entrenado levenberg marquardt     4.2 control inverso entrenado regularizacin   bayesián   posteriormente entrenar neuro-controlador inverso   usar aprendizaje regularizacin bayesián   figura 9 10 observar comportamiento tpico   neuro-controlador observar   seguimiento seal referencia   presentado seccin 4.1 adems esfuerzo control   presentar oscilación notoria          fig. 9 respuesta temporal neuro-controlador entrenado   regularizacin bayesián lneo punteado referencia lneo definido salida   planta       fig. 10 respuesta temporal esfuerzo control neuro-controlador   entrenado regularizacin bayesián        6       figura 11 12 observar comportamiento   neuro-controlador entrenado regularizacin   bayesián funcion obsrvese seguimiento   referencia impulso esfuerzo   control oscilación menor amplitud       fig. 11 respuesta temporal neuro-controlador entrenado   regularizacin bayesián lneo punteado referencia lneo definido salida   planta         fig. 12 respuesta temporal esfuerzo control neuro-controlador   entrenado regularizacin bayesián     4.3 ndiz desempeo   estimar cualitativamente desempeo   controlador entrenado levenberg marquardt   regularizacin bayesián calcular ndiz   desempeo promedio error absoluto promedio   esfuerzo control      tabla i. ndiz desempeo controlador levenberg   marquardt regularizacin bayesián       levenberg   marquardt   regularizacin   bayesián   promedio error   absoluto   0.2434632   0.08789647   ndice esfuerzo   control   3.81427187   3.74021221     analizar ndiz desempeo obtenido   concluir seguimiento neuro-controlador entrenado   regularizacin bayesián logrado   levenberg marquardt menor valor   promedio error absoluto   situacin similar   esfuerzo control neuro-controlador   entrenado regularizacin bayesián presentar menor   valor ndice desempeo      5 conclusión   efecto sobre-entrenamiento   entrenamiento neuro-controlador inverso mejorar    desempeo     desempeo neuro-controlador entrenado   aprendizaje bayesiano explicar   estrategia entrenamiento permitir obtener red neuronal   mejor capacidad generalizacin dato   entrenamiento contaminado ruido   concordante observado lopez 07     continuar trabajo pretender desarrollar estudio   comparativo neuro-controlador inverso entrenado   algoritmo mencionado artculo generar   conclusión ms general      posibilidad complementar trabajo   algoritmo aprendizaje presentado   documento ejemplo tcnica entrenamiento   basada gradiente conjugado     referencia     bishop c. 1995 neural networks for pattern recognition   oxford press new york   foreseir f. d. and hacer m. t. 1997 gauss-newton   approximation   to   bayesiar   regularization   in   proceedings of the 1997 international joint conference   on neural networks   hacer m. demuth and beale m. 1996 neural networks   design pws publishing company united stat   haykin s. 1999 neural networks comprehensivir   foundation second edition prentacer hall   hornik k. 1989 multilayer feedforward networks are   universal approximators neural networks 2:359366   lopez j.and caicedo e. 2005 entrenamiento bayesiano   red neuronal artificial in memoria   congreso internacional inteligencia computacional   lopez j.and caicedo e. 2007 identificacin sistema   usar red neuronal entrenado aprendizaje   bayesiano memoria congreso internacional   inteligencia computacional   mackay d. 1996 practical bayesian framework for   backpropagation networks neural computation 4:448 472 1992   masters t. 1995 advanced algorithms for neural network   c++ sourcebook john wiley sons inc    narendro k. s. k. parthasarathy 1990 identification and   control of dynamical systems using neural networks   ieee trans on neural networks v.1,no 1 pp.4-27    norgaard m. 2000 neural networks for modelling and   control of dynamic systems springer   verlag    london  