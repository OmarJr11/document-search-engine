control neuronal modelo inverso servosistema usar algoritmo aprendizaje bayesiano victor jaime garzn jess lpez viii congreso asociacin colombiano automtica universidad tecnolgico bolvar asociacin colombiano automtica abril cartagena isbn control neuronal modelo inverso servosistema usar algoritmo aprendizaje bayesiano victor jaime garzn jess lpez grupo investigacin bionanoelectrnica escuela ingeniera elctrico electrnico universidad valle cali colombia email escuela ingeniera elctrico electrnico universidad valle cali colombia email grupo investigacin energa departamento automtica electrnico calle universidad autnoma occidente cali colombia resumen trabajo presentar resultado experimental control neuronal velocidad servosistema estrategia control neuronal implementado control modelo inverso entrenamiento red usar algoritmo aprendizaje regularizacin bayesián evalar capacidad generalizacin mtodo funcin correcto funcionamiento controlador seguir seal referencia esfuerzo control obtenido palabra clave red neuronal artificial algoritmo entrenamiento control dinmica inverso introduccin propiedad ms explotada red neuronal artificial rna aproximador universal función hornik llevar utilizarlas diversidad aplicación reconocimiento patrón bishop identificacin control sistema dinmico narendra rea control sistema dinmico rna usar enfoque control neuronal modelo inverso estrategia bsico control neuronal norgaard adems sealar él existir diversidad algoritmo aprendizaje red neuronal ms usado algoritmo basado gradiente depender utilizar informacin gradiente algoritmo aprendizaje denominado orden gradiente descendente hacer haykin algoritmo aprendizaje ms elaborado denominado orden algoritmo gradiente conjugado hacer haykin algoritmo basado metodologa hacer masters aplicación control neuronal modelo inverso generalmente seleccionar algoritmo aprendizaje basado principalmente rapidez convergencia error suficientemente pequeo acorde necesidad usuario alcanzar error pequeo garantizar capacidad generalizacin modelo neuronal producir caso problema significar red presentar error patrón entrenamiento error aumentar patrón validacin alternativa evitar entrenamiento destacar algoritmo regularizacin automtico aprendizaje bayesiano aplicación identificacin sistema explorar tener resultado calidad modelo neuronal mejorar aprendizaje bayesiano aprendizaje convencional lopez objetivo trabajo diferencia controlador neuronal entrenado mtodo garantizar capacidad generalizacin mtodo considerar aspecto aprendizaje bayesiano documento est organizado seccin presentar concepto general control neuronal entrenamiento red neuronal considerar posteriormente seccin presentar implementacin control neuronal modelo inverso servosistema seccin mostrar resultado experimental trabajo terminar seccin presentar conclusión control modelo inverso aprendizaje bayesiano modelo inverso control modelo inverso tcnico buscar cancelar dinmica planta colocar elemento cascado caso red neuronal aproximacin matemtico inverso planta buscar salida ms parecida referencia norgaard tendencia realizar control neuronal modelo inverso conocido entrenamiento general red neuronal usar dato obtenido anterioridad modelo inverso planta red neuronal entrenar controlador cancelar dinmica planta observar esquema control modelo inverso tendencia conocido entrenamiento especializado esquema control adaptativo objetivo minimizar error salida planta salida modelo referencia norgaard entrenamiento requerir red neuronal entrenado modelo directo planta estructura entrenamiento inversoespecializado algoritmo aprendizaje lm ecuacin presentar cmo localizar valor mnimo xmin funcin variable utilizar derivado mtodo newton min min min min t x f t x f t x t x base ecuacin inferir minimizar error global ep espacio peso sinptico representado matriz p p t t w w derivada error global ep corresponder matriz hessián h derivada ep conocer vector gradiente vector gradiente matriz hessián funcin error calcular utilizar regla cadena as vector gradiente est compuesto derivado parcial error peso wi red elemento i j matriz hessián calcular segundo derivado parcial error peso wi wj carga computacional implicar calcular exacto matriz h estimacin master introducir mecanismo control evitar problema poder actualizacin pesos red dar origen g i h w w t t mecanismo control garantizar convergencia algoritmo consistir introducir factor lugar probar ecuacin mtodo newton evaluar él algoritmo converge valor error comenzar crecer eliminar valor incrementar valor minimizar efecto matriz h actualizacin peso efecto matriz h prcticamente desaparecer actualizacin peso esencialmente algoritmo gradiente descendente algoritmo claro tendencia convergencia disminuir valor aumentar efecto matriz h garantizar algoritmo comportar predominio mtodo newton mtodo levenberg marquardt mezclar sutilmente mtodo newton mtodo gradiente descendente nico ecuacin estimar actualizacin peso red neuronal regularizacin algoritmo aprendizaje regularizacin bayesián br aplicación observar red neuronal artificial caer problema conocido bishop red capaz responder adecuadamente dato entrada dato utilizar proceso aprendizaje problema solucionar visto red especializar memorizar conjunto dato determinado error pequeo traer consecuencia error test verificacin red planta rna modelo inverso rnar modelo directo salido entrada modelo referencia salido estimado entrenamiento indeseable red est trabajar solucin aplicacin especfico surgir tcnica denominado regularizacin cuyo objetivo minimizar fenmeno ende efecto fenmeno ms evidente dato entrada estn contaminado ruido objetivo regularizacin garantizar adecuado aprendizaje evitar problema regularizacin parada temprano proceso aprendizaje definir tipo error aprendizaje cuyo evolucin mostrir figura lnea continuo calcular diferencia salida red valor deseado error utilizar modificar peso red tcnica surgir error denomina validacin cuyo evolucin mostrar lneo punteado calcular diferencia salida red valor deseado evaluado dato entrada pertenecer conjunto dato validacin importante aclarar error modificacin peso sinptico red momento observar comportamiento red frente dato pertenecer conjunto universo problema utilizado entrenamiento iteración error cuadrtico regularizacin parada temprano lneo continuo error entrenamiento lneo punteado error validacin observar error entrenamiento seguir decreceir error validacin comenz subir seal evitar él recomendar detener proceso entrenamiento red justo error validacin empiecir tendencia ascendente razn llamar regularizacin parada temprano bishop evitar proceso aprendizaje contine disminuir excesivamente error entrenamiento tomar criterio finalizacin tendencia ascendente error validacin regularizacin limitacin magnitud peso experiencia mostrar garantizar funcin salida suave lograr mantener peso sinptico red valor relativamente pequeo bishop limitar magnitud peso redefinar clculo error as w d r error calcular trmino utilizar notacin denominar er error regularizado trmino corresponder error cuadrtico promedio presentado forma tradicionalmente estimar error entrenamiento afectado parmetro m k pk pk p p d d p trmino utilizado estimar error aprendizaje regularizado introducir sumatoria peso sinptico red mostrado ponderado parmetro algoritmo aprendizaje tender minimizar er resultado sumatoria peso igualmente tender minimizar garantizar suavidad salida red n n n w w regularizacin bayesián trabajar tcnica error regularizado mostrado inconveniente definir parmetro conseguir efecto minimizar lopez regularizacin bayesián tcnica entrenamientir red neuronal abordo perspectiva probabilstico distribucin probabilidad valor peso mackay tcnica regularizacin tambin denominar regularizacin automticar trabajar error regularizado forma algoritmo aprendizaje valor ms adecuado parmetro regularizant foresee control neuronal modelo inverso motor dc servosistema motor dc proceso controlar utiliz motor dc cuyo eje est acoplado disco pretender controlar velocidad rotacin planta dato enviar pc motor travs tarjeta adecuacin registro directo permanente velocidad obtenido tacmetro observar fotografa servosistema controlar servomecanismo controlar servosistema poseer zona muerto zona saturacin detectado par valor convertir cota superior inferior proceso identificacin entrenamiento red neuronal accin control operar forma deseado rango trabajo control neuronal modelo inverso motor dc idea control tcnica neuronal inicialmente planteado narenda objetivo aprovechar capacidad aprendizaje red neuronal entrenar red poder usar controlador inicialmente realizar control modelo inverso norgaard modelo inverso caso estudio red neuronal convenientemente entrenado hacer labor controlador arquitectura interno red neuronal red neuronal realizar control red tipo perceptron multicapa capa oculto red entrada valor referencia muestra actual salida sistema muestra salida sistema muestra accin control accin control retardo informacin red estimar accin control aplicar proceso capa oculto est conformado neurona función activacin descripcin experimento definir experimento realiz prueba estable identificar zona muerto zona saturacin determinar regin operacin motor mencion seccin valor estn respectivamente toma dato entrenar controlador neuronal modelo inverso experimento tomar dato funcionamiento motor regin operacin experimento aplicar escalón amplitud aleatorio motor duracin escaln garantizar estabilizacin velocidad motor usar tarjeta adquisicin dato capturan seal entrada salida velocidad servomecanismo realizacin experimento herramienta labview entrenamientir red neuronal esquema control neuronal utilizado control neuronal inverso general caso modelo inverso entrar usar toolbox red neuronal matlab entrenamiento red neuronal utiliz mtodo entrenamiento aprendizaje basado levenberg marquardt aprendizaje regularizacin bayesián resultado experimental entrenar red neuronal estrategia entrenamiento mencionado proceder verificar comportamiento obtenido verificacin implement aplicacin herramienta labview tomar peso red neuronal entrenado matlab controlador inverso usar esquema similar figura valer pena mencionar red probado obtener error entrenamiento similar verificar pruer controlar planta capacidad generalizacin control inverso entrenado levenberg marquardt usar servosistema obtenido entrenamiento basado metodologa levenberg marquardt figura observar comportamiento tpico observar funcionamiento ms adecuado lograr seguimiento seal referencia esfuerzo control oscilatorio respuesta temporal entrenado levenberg marquardt lneo punteado referencia lneo definido salida planta respuesta temporal esfuerzo control entrenado levenberg marquardt realizar prueba entrenamiento metodologa encontrar cumplierar satisfactorio control servosistema figura observar controlador obtenido lograr seguimiento seal referencia caso esfuerzo control seguir oscilatorio respuesta temporal entrenado levenberg marquardt lneo punteado referencia lneo definido salida planta respuesta temporal esfuerzo control entrenado levenberg marquardt control inverso entrenado regularizacin bayesián posteriormente entrenar inverso usar aprendizaje regularizacin bayesián figura observar comportamiento tpico observar seguimiento seal referencia presentado seccin adems esfuerzo control presentar oscilación notoria respuesta temporal entrenado regularizacin bayesián lneo punteado referencia lneo definido salida planta respuesta temporal esfuerzo control entrenado regularizacin bayesián figura observar comportamiento entrenado regularizacin bayesián funcion obsrvese seguimiento referencia impulso esfuerzo control oscilación menor amplitud respuesta temporal entrenado regularizacin bayesián lneo punteado referencia lneo definido salida planta respuesta temporal esfuerzo control entrenado regularizacin bayesián ndiz desempeo estimar cualitativamente desempeo controlador entrenado levenberg marquardt regularizacin bayesián calcular ndiz desempeo promedio error absoluto promedio esfuerzo control tabla ndiz desempeo controlador levenberg marquardt regularizacin bayesián levenberg marquardt regularizacin bayesián promedio error absoluto ndice esfuerzo control analizar ndiz desempeo obtenido concluir seguimiento entrenado regularizacin bayesián logrado levenberg marquardt menor valor promedio error absoluto situacin similar esfuerzo control entrenado regularizacin bayesián presentar menor valor ndice desempeo conclusión efecto entrenamiento inverso mejorar desempeo desempeo entrenado aprendizaje bayesiano explicar estrategia entrenamiento permitir obtener red neuronal mejor capacidad generalizacin dato entrenamiento contaminado ruido concordante observado lopez continuar trabajo pretender desarrollar estudio comparativo inverso entrenado algoritmo mencionado artculo generar conclusión ms general posibilidad complementar trabajo algoritmo aprendizaje presentado documento ejemplo tcnica entrenamiento basada gradiente conjugado referencia bishop neural networks for pattern recognition oxford press new york foreseir and hacer approximation to bayesiar regularization in proceedings of the international joint conference on neural networks hacer demuth and beale neural networks design pws publishing company united stat haykin neural networks comprehensivir foundation second edition prentacer hall hornik multilayer feedforward networks are universal approximators neural networks lopez caicedo entrenamiento bayesiano red neuronal artificial in memoria congreso internacional inteligencia computacional lopez caicedo identificacin sistema usar red neuronal entrenado aprendizaje bayesiano memoria congreso internacional inteligencia computacional mackay practical bayesian framework for backpropagation networks neural computation masters advanced algorithms for neural network sourcebook john wiley sons inc narendro parthasarathy identification and control of dynamical systems using neural networks ieee trans on neural networks norgaard neural networks for modelling and control of dynamic systems springer verlag london